# DeepLearning_Study_W8

稠密连接：每层以之前层的输出为输入，对于有L层的传统网络，一共有L个连接，对于DenseNet，则有L(L+1)2。

Growth rate：由于每个层的输入是所有之前层输出的连接，因此每个层的输出不需要像传统网络一样多。这里Hl(.)的输出的特征图的数量都为k，k即为Growth Rate，用来控制网络的“宽度”（特征图的通道数）.比如说第l层有k(l−1)+k0的输入特征图，k0是输入图片的通道数。

虽然说每个层只产生k个输出，但是后面层的输入依然会很多，因此引入了Bottleneck layers 。本质上是引入1x1的卷积层来减少输入的数量，Hl的具体表示如下
BN−>ReLU−>Conv(1×1)−>BN−>ReLU−>Conv(3×3)
